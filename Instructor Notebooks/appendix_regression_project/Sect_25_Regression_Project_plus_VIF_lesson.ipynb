{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 25: Complete Data Science Project with Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Repeat the Mod 1 Project analysis in a streamlined way.\n",
    "\n",
    "- Learn about `pandas_profiling` for quick and easy EDA (don't use on Mod Projects please).\n",
    "\n",
    "- Intro to the idea of pipelines / programmatic construction of models\n",
    "\n",
    "- Learn about [Variance Inflation Factor](https://etav.github.io/python/vif_factor_python.html) and how to use it to address multicollinearity. ( [Wikipedia: VIF](https://en.wikipedia.org/wiki/Variance_inflation_factor))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions?\n",
    "- Checking for normality and what to do about it.\n",
    "- Checking how much scaling affects the output\n",
    "\n",
    "### Follow Ups\n",
    "- Question regarding removal high VIF variables and if the others that were identified as high VIF would still be high after removing an initial VIF>5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T22:18:47.588104Z",
     "start_time": "2020-07-17T22:18:47.584900Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import statsmodels.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "#\n",
    "# import pandas_profiling\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T22:18:47.593134Z",
     "start_time": "2020-07-17T22:18:47.589750Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U fsds\n",
    "from fsds.imports import *\n",
    "# Set pandas options\n",
    "pd.set_option('display.precision',3)\n",
    "pd.set_option('display.max_columns',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T22:23:38.681380Z",
     "start_time": "2020-07-17T22:23:38.280005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YrSold</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8450</td>\n",
       "      <td>208500</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9600</td>\n",
       "      <td>181500</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1786</td>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>11250</td>\n",
       "      <td>223500</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>1915</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9550</td>\n",
       "      <td>140000</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2198</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>14260</td>\n",
       "      <td>250000</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YrSold  MoSold  Fireplaces  TotRmsAbvGrd  GrLivArea  FullBath  YearRemodAdd  YearBuilt  OverallCond  OverallQual  LotArea  SalePrice BldgType HouseStyle\n",
       "Id                                                                                                                                                          \n",
       "1     2008       2           0             8       1710         2          2003       2003            5            7     8450     208500     1Fam     2Story\n",
       "2     2007       5           1             6       1262         2          1976       1976            8            6     9600     181500     1Fam     1Story\n",
       "3     2008       9           1             6       1786         2          2002       2001            5            7    11250     223500     1Fam     2Story\n",
       "4     2006       2           1             7       1717         1          1970       1915            5            7     9550     140000     1Fam     2Story\n",
       "5     2008      12           1             9       2198         2          2000       2000            5            8    14260     250000     1Fam     2Story"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fs.datasets.load_ames_train(subset=True,read_csv_kwds={'index_col':0}).reset_index()#fs.datasets.load_mod1_proj()\n",
    "\n",
    "df2 = fs.datasets.load_ames_train(subset=False,read_csv_kwds=dict(index_col=0))#.reset_index()#fs.datasets.load_mod1_proj()\n",
    "bldg_house_style = df2.select_dtypes('object')[['BldgType','HouseStyle']].reset_index()\n",
    "\n",
    "## Merge \n",
    "df = pd.merge(df,bldg_house_style,on='Id')\n",
    "df.set_index('Id',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T22:27:35.334231Z",
     "start_time": "2020-07-17T22:27:35.324872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 1 to 1460\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   YrSold        1460 non-null   int64 \n",
      " 1   MoSold        1460 non-null   int64 \n",
      " 2   Fireplaces    1460 non-null   int64 \n",
      " 3   TotRmsAbvGrd  1460 non-null   int64 \n",
      " 4   GrLivArea     1460 non-null   int64 \n",
      " 5   FullBath      1460 non-null   int64 \n",
      " 6   YearRemodAdd  1460 non-null   int64 \n",
      " 7   YearBuilt     1460 non-null   int64 \n",
      " 8   OverallCond   1460 non-null   int64 \n",
      " 9   OverallQual   1460 non-null   int64 \n",
      " 10  LotArea       1460 non-null   int64 \n",
      " 11  SalePrice     1460 non-null   int64 \n",
      " 12  BldgType      1460 non-null   object\n",
      " 13  HouseStyle    1460 non-null   object\n",
      "dtypes: int64(12), object(2)\n",
      "memory usage: 171.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T22:28:57.634646Z",
     "start_time": "2020-07-17T22:28:57.629525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1Story', '2Story', '1.5Fin', 'SLvl', 'SFoyer', '1.5Unf', '2.5Unf',\n",
       "       '2.5Fin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HouseStyle'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T22:27:45.393692Z",
     "start_time": "2020-07-17T22:27:45.378091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OneFam</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OneFam</td>\n",
       "      <td>1Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OneFam</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OneFam</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OneFam</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>OneFam</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>OneFam</td>\n",
       "      <td>1Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>OneFam</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>OneFam</td>\n",
       "      <td>1Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>OneFam</td>\n",
       "      <td>1Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BldgType HouseStyle\n",
       "Id                      \n",
       "1      OneFam     2Story\n",
       "2      OneFam     1Story\n",
       "3      OneFam     2Story\n",
       "4      OneFam     2Story\n",
       "5      OneFam     2Story\n",
       "...       ...        ...\n",
       "1456   OneFam     2Story\n",
       "1457   OneFam     1Story\n",
       "1458   OneFam     2Story\n",
       "1459   OneFam     1Story\n",
       "1460   OneFam     1Story\n",
       "\n",
       "[1460 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T22:27:16.101485Z",
     "start_time": "2020-07-17T22:27:16.097758Z"
    }
   },
   "outputs": [],
   "source": [
    "## Fix Col Names with Numbers\n",
    "repl_dict = {'1Fam':'OneFam','2fmCon':'TwoFmCon'}\n",
    "\n",
    "df['BldgType'] = df['BldgType'].replace(repl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T22:27:16.359525Z",
     "start_time": "2020-07-17T22:27:16.354194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneFam      1220\n",
       "TwnhsE       114\n",
       "Duplex        52\n",
       "Twnhs         43\n",
       "TwoFmCon      31\n",
       "Name: BldgType, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BldgType'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T22:27:18.978096Z",
     "start_time": "2020-07-17T22:27:18.969590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 1 to 1460\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   YrSold        1460 non-null   int64 \n",
      " 1   MoSold        1460 non-null   int64 \n",
      " 2   Fireplaces    1460 non-null   int64 \n",
      " 3   TotRmsAbvGrd  1460 non-null   int64 \n",
      " 4   GrLivArea     1460 non-null   int64 \n",
      " 5   FullBath      1460 non-null   int64 \n",
      " 6   YearRemodAdd  1460 non-null   int64 \n",
      " 7   YearBuilt     1460 non-null   int64 \n",
      " 8   OverallCond   1460 non-null   int64 \n",
      " 9   OverallQual   1460 non-null   int64 \n",
      " 10  LotArea       1460 non-null   int64 \n",
      " 11  SalePrice     1460 non-null   int64 \n",
      " 12  BldgType      1460 non-null   object\n",
      " 13  HouseStyle    1460 non-null   object\n",
      "dtypes: int64(12), object(2)\n",
      "memory usage: 171.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRUB / EXPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols =['id','date','view']\n",
    "\n",
    "df.drop(drop_cols, axis=1,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replacing Values\n",
    "repl_dict = {'sqft_basement':('?','0.0')}\n",
    "\n",
    "for col,replace in repl_dict.items():\n",
    "    df[col] = df[col].replace(replace[0], replace[1])\n",
    "    display(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recasting datatypes\n",
    "recast_dict = {'sqft_basement':'float'}\n",
    "for col,dtype in recast_dict.items():\n",
    "    df[col] = df[col].astype(dtype)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Null values / zeros\n",
    "fillna_dict = {'waterfront':0,\n",
    "              'yr_renovated':0}\n",
    "\n",
    "for col,val in fillna_dict.items():\n",
    "    df[col].fillna(val,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_ols_f(df,target='price',cat_cols = ['zipcode','grade'],\n",
    "               col_list=None, show_summary=True,exclude_cols=[]):\n",
    "    \n",
    "    if col_list is None:\n",
    "        col_list = list(df.drop(target,axis=1).columns)\n",
    "        \n",
    "    ## remove exclude cols\n",
    "    [col_list.remove(ecol) for ecol in exclude_cols if ecol in col_list]\n",
    "\n",
    "    features = '+'.join(col_list)\n",
    "\n",
    "\n",
    "    for col in cat_cols:\n",
    "        features = features.replace(col,f\"C({col})\")\n",
    "\n",
    "\n",
    "\n",
    "    formula = target+'~'+features #target~predictors\n",
    "\n",
    "    model = smf.ols(formula=formula, data=df).fit()\n",
    "    \n",
    "    if show_summary:\n",
    "        display(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "## diagnostic function\n",
    "\n",
    "def diagnose_model(model):\n",
    "    resids = model.resid\n",
    "    \n",
    "    fig,ax = plt.subplots(ncols=2,figsize=(10,5))\n",
    "    sms.qqplot(resids, stats.distributions.norm,\n",
    "              fit=True, line='45',ax=ax[0])\n",
    "    xs = np.linspace(0,1,len(resids))\n",
    "    ax[1].scatter(x=xs,y=resids)\n",
    "    \n",
    "    return fig,ax \n",
    "\n",
    "model = make_ols_f(df)\n",
    "diagnose_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How does our model look? \n",
    "    - Clearly have not addressed normality \n",
    "        - First apply outlier removal  \n",
    "        - Then try logging as a follow up\n",
    "        \n",
    "- What haven't we addressed yet?\n",
    "    - Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revised Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_Z(df,col):\n",
    "    \"\"\"Use scipy to calcualte absoliute Z-scores \n",
    "    and return boolean series where True indicates it is an outlier\n",
    "    Args:\n",
    "        col (Series): a series/column from your DataFrame\n",
    "    Returns:\n",
    "        idx_outliers (Series): series of  True/False for each row in col\n",
    "        \n",
    "    Ex:\n",
    "    >> idx_outs = find_outliers(df['bedrooms'])\n",
    "    >> df_clean = df.loc[idx_outs==False]\"\"\"\n",
    "    from scipy import stats\n",
    "\n",
    "    col = df[col]\n",
    "    z = np.abs(stats.zscore(col))\n",
    "    idx_outliers = np.where(z>3,True,False)\n",
    "    return idx_outliers\n",
    "\n",
    "def find_outliers_IQR(df,col):\n",
    "    res = df[col].describe()\n",
    "    IQR = res['75%'] -  res['25%']\n",
    "    lower_limit = res['25%'] - 1.5*IQR\n",
    "    upper_limit = res['75%'] + 1.5*IQR\n",
    "    \n",
    "    idx_goodvals = (df[col]<upper_limit) & (df[col]>lower_limit) \n",
    "    \n",
    "    return ~idx_goodvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_outliers_z = find_outliers_Z(df,'bedrooms')\n",
    "# idx_outliers.sum()\n",
    "idx_outliers_z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_outliers_IQR = find_outliers_IQR(df,'bedrooms')\n",
    "# idx_outliers.sum()\n",
    "idx_outliers_IQR.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers_Z = pd.DataFrame()\n",
    "df_outliers_IQR = pd.DataFrame()\n",
    "\n",
    "for col in df.columns:\n",
    "    df_outliers_Z[col] = find_outliers_Z(df,col)\n",
    "    df_outliers_IQR[col] = find_outliers_IQR(df,col)\n",
    "\n",
    "idx_outs_IQR = df_outliers_IQR.any(axis=1)\n",
    "idx_outs_z= df_outliers_Z.any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idx_outs_z.sum()/len(idx_outs_z)*100)\n",
    "print(idx_outs_IQR.sum()/len(idx_outs_IQR)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop zscore outleirs\n",
    "df.loc[idx_outs_z==True].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.loc[idx_outs_z ==False]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revised Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Work Tracker (How long did the project take me?):**\n",
    "- Start: 12/10/19 ~8:45pm \n",
    "- End: 12/10/19 11:00 pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model2 = make_ols_f(df)\n",
    "diagnose_model(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore 2: Multicollinearity with VIF\n",
    "\n",
    "Definition: when 2 features are more related to each than the target.\n",
    "\n",
    "> $\\large V.I.F. = \\frac{1}{(1 - R^2)} $<br>\n",
    "- [VIF (Variance Inflation Factor)](https://etav.github.io/python/vif_factor_python.html) \n",
    "- [Wikipedia: VIF](https://en.wikipedia.org/wiki/Variance_inflation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.ihelp(fs.ds.list2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vif_ols(df,exclude_col = None, cat_cols = ['grade','zipcode']):\n",
    "    # let's check each column, build a model and get the r2\n",
    "    vif_scores = [['Column','VIF','R2']]\n",
    "\n",
    "    if exclude_col is not None:\n",
    "        df = df.drop(exclude_col,axis=1)\n",
    "        \n",
    "    for column in df.columns:\n",
    "        columns_to_use = df.drop(columns=[column]).columns\n",
    "        target = column\n",
    "        linreg = make_ols_f(df, target=target, cat_cols=cat_cols,\n",
    "                            col_list=columns_to_use,show_summary=False)\n",
    "        R2 = linreg.rsquared\n",
    "        VIF = 1 / (1 - R2)\n",
    "    #     print(f\"VIF for {column} = {VIF}\")\n",
    "        vif_scores.append([column, VIF, R2])\n",
    "\n",
    "    res = fs.ds.list2df(vif_scores,index_col='Column')\n",
    "    res.sort_values('VIF',ascending=False,inplace=True)\n",
    "    res['use']=res['VIF'] <5\n",
    "    return res\n",
    "\n",
    "res = vif_ols(df,exclude_col='price',)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = vif_ols(df,exclude_col=['price','sqft_above'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_scores = [['Column','VIF','R2']]\n",
    "model_target= 'price'\n",
    "\n",
    "for col in df.drop(model_target,axis=1).columns:\n",
    "    \n",
    "    columns_to_use = df.drop(columns=[col]).columns\n",
    "    \n",
    "    target=col\n",
    "#     cat_cols = \n",
    "    linreg = make_ols_f(df,target,show_summary=False)\n",
    "    R2 = linreg.rsquared\n",
    "    \n",
    "    VIF = 1/ (1-R2)\n",
    "    \n",
    "    vif_scores.append([col,VIF,R2])\n",
    "    \n",
    "res = fs.ds.list2df(vif_scores,index_col='Column')\n",
    "res.sort_values('VIF',ascending=False,inplace=True)\n",
    "res['use']=res['VIF'] <5\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(df.corr())\n",
    "fs.jmi.multiplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res['use']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use = df[res[res['use']].index]\n",
    "df_use['price'] = df['price'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Interpretations/Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model3 = make_ols_f(df_use)\n",
    "diagnose_model(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = vif_ols(df,exclude_col=['price','sqft_above'])\n",
    "df_use2 = df[res2[res2['use']].index]\n",
    "df_use2['price'] = df['price'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model4 = make_ols_f(df_use2)#,exclude_cols=['floors','lat','waterfront'])\n",
    "diagnose_model(model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Vars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check_normality(df,col):\n",
    "    \n",
    "    sns.distplot(df[col])\n",
    "    plt.show()\n",
    "    \n",
    "    stat,p = stats.normaltest(df[col])\n",
    "    \n",
    "    return p\n",
    "\n",
    "p_list = [['Column','Pval']]\n",
    "for col in df.columns:\n",
    "    p_list.append([col,check_normality(df,col)])\n",
    "    \n",
    "p_list = fs.ds.list2df(p_list)\n",
    "p_list['reject'] = p_list['Pval']<0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list=['price','sqft_living15','sqft_lot','sqft_lot15']\n",
    "for col in log_list:\n",
    "    df[col+'_log'] = np.log(df[col])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logged = df.copy()\n",
    "df_logged.drop(log_list,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model5 = make_ols_f(df_logged,target='price_log')#,exclude_cols=['sqft_basement',\n",
    "#                                                        'yr_built'])\n",
    "diagnose_model(model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_cols = ['zipcode','grade']\n",
    "# cat_cols.extend([''])\n",
    "df = df_logged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# df_minmax = \n",
    "cat_cols = ['zipcode','grade']\n",
    "cols_to_drop =cat_cols\n",
    "\n",
    "cols_to_drop.append('price_log')\n",
    "cols_to_scale = df.drop(cols_to_drop,axis=1).columns\n",
    "# cols_to\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "minmax_data = scaler.fit_transform(df[cols_to_scale])\n",
    "\n",
    "df_minmax = pd.DataFrame(minmax_data,columns=cols_to_scale)\n",
    "df_minmax['price_log'] = df['price_log'].copy()\n",
    "df_minmax['zipcode']= df['zipcode']\n",
    "df_minmax['grade']= df['grade']\n",
    "\n",
    "df_minmax.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_default = make_ols_f(df_logged,target='price_log',cat_cols=cat_cols)\n",
    "diagnose_model(model_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_minmax = make_ols_f(df_minmax,target='price_log',cat_cols=cat_cols)\n",
    "diagnose_model(model_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# df_minmax = \n",
    "cat_cols = ['zipcode','grade']\n",
    "cols_to_drop =cat_cols\n",
    "\n",
    "cols_to_drop.append('price_log')\n",
    "cols_to_scale = df.drop(cols_to_drop,axis=1).columns\n",
    "# cols_to\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df[cols_to_scale])\n",
    "\n",
    "df_standard = pd.DataFrame(scaled_data,columns=cols_to_scale)\n",
    "df_standard['price_log'] = df['price_log'].copy()\n",
    "df_standard['zipcode']= df['zipcode']\n",
    "df_standard['grade']= df['grade']\n",
    "\n",
    "df_standard.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_standard = make_ols_f(df_standard,target='price_log',cat_cols=cat_cols)\n",
    "diagnose_model(model_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# df_minmax = \n",
    "cat_cols = ['zipcode','grade']\n",
    "cols_to_drop =cat_cols\n",
    "\n",
    "# cols_to_drop.append('price_log')\n",
    "cols_to_scale = df.drop(cols_to_drop,axis=1).columns\n",
    "# cols_to\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df[cols_to_scale])\n",
    "\n",
    "df_standard = pd.DataFrame(scaled_data,columns=cols_to_scale)\n",
    "# df_standard['price_log'] = df['price_log'].copy()\n",
    "df_standard['zipcode']= df['zipcode']\n",
    "df_standard['grade']= df['grade']\n",
    "\n",
    "df_standard.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_standard = make_ols_f(df_standard,target='price_log',\n",
    "                            exclude_cols=['zipcode','grade','sqft_lot_log'])#cat_cols=cat_cols)\n",
    "diagnose_model(model_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- Scaling is not necessarily as helpful as dogma would indicate (at least with statsmodels).\n",
    "- VIF identified new columns as multicoll that heatmap correlation did not indicate (according to pairwise comparisons). \n",
    "- log transformation was indeed helpful (though slightly complicates interpretation)\n",
    "\n",
    "- IQR outier removal is more potent/liberal than using Z-scores\n",
    "    - Did not check if IQR outlier removal would have provided better results.\n",
    "    - We could not apply IQR across the board without removing all of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
