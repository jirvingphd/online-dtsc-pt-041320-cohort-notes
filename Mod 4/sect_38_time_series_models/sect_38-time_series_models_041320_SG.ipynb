{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sect 38: Time Series Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10/23/20\n",
    "- online-ds-pt-041320"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives:\n",
    "\n",
    "- Revisit types of time series trends and how to remove them.\n",
    "- Revisit seasonal decomposition`statsmodels.tsa.seasonal.seasonal_decompose`\n",
    "\n",
    "- Learn about PACF, ACF\n",
    "- Introduce ARIMA and SARIMA models.\n",
    "- Activity: SARIMA Models - Lab\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing the End of Sect 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:53:32.637618Z",
     "start_time": "2020-10-23T22:53:32.611702Z"
    }
   },
   "outputs": [],
   "source": [
    "from fsds.imports import *\n",
    "pd.set_option('precision',3)\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "df = pd.read_csv('baltimore_crime_2020_ts_041320pt.csv',\n",
    "                 index_col=0,parse_dates=[0])\n",
    "## Lazy fix to not changine col names to lowercase last class\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "df.index.freq = 'D'\n",
    "display(df.head())\n",
    "\n",
    "# df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:53:34.588336Z",
     "start_time": "2020-10-23T22:53:34.150581Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = df.plot()\n",
    "ax.legend(bbox_to_anchor=([1,1]))\n",
    "ax.set(title=f'Baltimore Crime Rates - {df.index.freq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trends/Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;font-size:2em\">Trends</div>\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-removing-trends-online-ds-ft-100719/master/images/new_trendseasonal.png\" width=80%>\n",
    "\n",
    "<div style=\"text-align:center;font-size:2em\">Mean</div>\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-types-of-trends-online-ds-ft-100719/master/images/new_mean_nonstationary.png\" width=70%>\n",
    "<br><br>\n",
    "<div style=\"text-align:center;font-size:2em\">Variance</div>\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-types-of-trends-online-ds-ft-100719/master/images/new_cov_nonstationary.png\" width=70%>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:53:37.350695Z",
     "start_time": "2020-10-23T22:53:37.342261Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def stationarity_check(TS,plot=True,col=None):\n",
    "    \"\"\"From: https://learn.co/tracks/data-science-career-v2/module-4-a-complete-data-science-project-using-multiple-regression/working-with-time-series-data/time-series-decomposition\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import adfuller\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "    if col is not None:\n",
    "        # Perform the Dickey Fuller Test\n",
    "        dftest = adfuller_test_df(TS[col])#adfuller(TS[col]) # change the passengers column as required \n",
    "    else:\n",
    "        dftest=adfuller_test_df(TS)#adfuller(TS)\n",
    " \n",
    "    if plot:\n",
    "        # Calculate rolling statistics\n",
    "        rolmean = TS.rolling(window = 8, center = False).mean()\n",
    "        rolstd = TS.rolling(window = 8, center = False).std()\n",
    "\n",
    "        #Plot rolling statistics:\n",
    "        fig = plt.figure(figsize=(12,6))\n",
    "        orig = plt.plot(TS, color='blue',label='Original')\n",
    "        mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "        std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Rolling Mean & Standard Deviation')\n",
    "        plt.show(block=False)\n",
    "    display(dftest)\n",
    "\n",
    "\n",
    "## Simpler Version of ADfullter func\n",
    "def adfuller_test_df(ts):\n",
    "    \"\"\"Returns the AD Fuller Test Results and p-values for the null hypothesis\n",
    "    that there the data is non-stationary (that there is a unit root in the data)\"\"\"\n",
    "    df_res = adfuller(ts)\n",
    "    names = ['Test Statistic','p-value','#Lags Used','# of Observations Used']\n",
    "    res  = dict(zip(names,df_res[:4]))\n",
    "    res['p<.05'] = res['p-value']<.05\n",
    "    res['Stationary?'] = res['p<.05']\n",
    "    \n",
    "    return pd.DataFrame(res,index=['AD Fuller Results'])\n",
    "\n",
    "# stationarity_check(ts);\n",
    "# adfuller_test_df(ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:53:39.719564Z",
     "start_time": "2020-10-23T22:53:39.466589Z"
    }
   },
   "outputs": [],
   "source": [
    "ts = df['larceny'].loc['2017':]\n",
    "stationarity_check(ts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Trends "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trend Removal Methods\n",
    "- Differencing (`.diff()`)\n",
    "- Log-Transformation (`np.log`)\n",
    "- Subtract Rolling Mean (`ts-ts.rolling().mean()`)\n",
    "- Subtract Exponentially-Weighted Mean (`ts-ts.ewm().mean()`)\n",
    "- Seasonal Decomposition (`from statsmodels.tsa.seasonal import seasonal_decompose`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:11:46.305444Z",
     "start_time": "2020-10-23T22:11:45.986812Z"
    }
   },
   "outputs": [],
   "source": [
    "## Differencing \n",
    "ts0 = ts.diff().dropna()\n",
    "ts0.plot()\n",
    "adfuller_test_df(ts0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:11:46.615371Z",
     "start_time": "2020-10-23T22:11:46.307136Z"
    }
   },
   "outputs": [],
   "source": [
    "## Log Transform\n",
    "ts3 = np.log(ts)\n",
    "ts3.plot()\n",
    "adfuller_test_df(ts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:11:46.915162Z",
     "start_time": "2020-10-23T22:11:46.616854Z"
    }
   },
   "outputs": [],
   "source": [
    "## Subtract Rolling mean\n",
    "ts2 = (ts - ts.rolling(3).mean()).dropna()\n",
    "ts2.plot()\n",
    "adfuller_test_df(ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:11:47.318976Z",
     "start_time": "2020-10-23T22:11:46.917801Z"
    }
   },
   "outputs": [],
   "source": [
    "## Subtract Exponentially Weight Mean Rolling mean\n",
    "ts4 = (ts - ts.ewm(halflife=7).mean()).dropna()\n",
    "ts4.plot()\n",
    "adfuller_test_df(ts4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:11:47.960599Z",
     "start_time": "2020-10-23T22:11:47.321295Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "plt.figure(figsize=(12,15))\n",
    "decomp= seasonal_decompose(ts)#,model='mul')\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sect 38: TIME SERIES MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Time Series models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- White Noise Model\n",
    "- Randon Walk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:11:58.771672Z",
     "start_time": "2020-10-23T22:11:58.315537Z"
    }
   },
   "outputs": [],
   "source": [
    "## Load in example time series\n",
    "plt.rcParams['figure.figsize'] = [12,5]\n",
    "nyse = fs.datasets.load_ts_nyse_monthly(read_csv_kwds={'parse_dates':True,\n",
    "                                                     'index_col':'Month'})\n",
    "exch = fs.datasets.load_ts_exch_rates(read_csv_kwds={'parse_dates':['Frequency'],\n",
    "                                                     'index_col':'Frequency'})\n",
    "trends = fs.datasets.load_ts_google_trends(read_csv_kwds={'skiprows':1,\n",
    "                                                         'parse_dates':['Month'],\n",
    "                                                         'index_col':['Month']})\n",
    "\n",
    "trends.columns= ['diet','gym','finance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White Noise Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- White noise is a true stationary time series.\n",
    "- 3 Properties:\n",
    "    - Fixed and constant mean\n",
    "    - Fixed and constant variance\n",
    "    - No correlation over time\n",
    "\n",
    "- Gaussian White Noise: A special case of a White Noise model is \n",
    "    - Mean is equal to zero\n",
    "    - variance is equal to 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:12:15.007652Z",
     "start_time": "2020-10-23T22:12:14.784098Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = nyse.plot(title='Example White Noise Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk Model\n",
    "- Two Properties:\n",
    "    - Has no specified mean or variance\n",
    "    - Has a strong dependence over time\n",
    "\n",
    "\n",
    "- The changes over time are basically a white noise model. \n",
    "\n",
    "$$\\large Y_t = Y_{t-1} + \\epsilon_t$$\n",
    "\n",
    "- Where $\\epsilon_t$ is a *mean zero* white noise model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:12:17.011798Z",
     "start_time": "2020-10-23T22:12:16.819972Z"
    }
   },
   "outputs": [],
   "source": [
    "exch['Euro'].plot(subplots=True,figsize=(12,4),title='Example Random Walk Model');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk with a Drift:\n",
    "- a drift parameter $c$, steering in a certain direction.\n",
    "$$\\large Y_t = c + Y_{t-1} + \\epsilon_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When a random walk is differenced it returns a white noise: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:12:27.627623Z",
     "start_time": "2020-10-23T22:12:27.424357Z"
    }
   },
   "outputs": [],
   "source": [
    "exch['Euro'].diff().plot(subplots=True,figsize=(12,4),\n",
    "                         title='Differenced Random Walks Become White Noise');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation, Autocorrelation & Partial Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:12:35.098051Z",
     "start_time": "2020-10-23T22:12:34.878485Z"
    }
   },
   "outputs": [],
   "source": [
    "trends.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:12:37.151902Z",
     "start_time": "2020-10-23T22:12:37.133970Z"
    }
   },
   "outputs": [],
   "source": [
    "## Correlation of Raw TS\n",
    "trends.corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Detrending Reveals Higher Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:12:44.709903Z",
     "start_time": "2020-10-23T22:12:44.484446Z"
    }
   },
   "outputs": [],
   "source": [
    "trends.diff().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:12:49.150357Z",
     "start_time": "2020-10-23T22:12:49.136573Z"
    }
   },
   "outputs": [],
   "source": [
    "## We Removed the Trend without Removing Seaonality\n",
    "trends.diff().corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:12:59.679725Z",
     "start_time": "2020-10-23T22:12:59.452164Z"
    }
   },
   "outputs": [],
   "source": [
    "## Seasonality causes correlations at specific times\n",
    "n=12\n",
    "ts = trends[['diet']]\n",
    "ts_shifted = ts.loc['2011':'2016']\n",
    "ts_shifted[f\"Shifted by {n}\"] = ts_shifted.shift(n)\n",
    "ts_shifted.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrating Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:04.047025Z",
     "start_time": "2020-10-23T22:13:03.873287Z"
    }
   },
   "outputs": [],
   "source": [
    "ts = trends['diet']\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:13.635510Z",
     "start_time": "2020-10-23T22:13:13.618742Z"
    }
   },
   "outputs": [],
   "source": [
    "## Generate 6 time-shifted columns\n",
    "total_shifts =6\n",
    "shifts = [ts.shift(x).rename(f\"Diet shifted {x}\") for x in range(total_shifts)]\n",
    "res = pd.concat(shifts,axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:16.318126Z",
     "start_time": "2020-10-23T22:13:16.063833Z"
    }
   },
   "outputs": [],
   "source": [
    "res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:17.507222Z",
     "start_time": "2020-10-23T22:13:17.495175Z"
    }
   },
   "outputs": [],
   "source": [
    "res.corr()[['Diet shifted 0']].style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:24.735760Z",
     "start_time": "2020-10-23T22:13:24.663495Z"
    }
   },
   "outputs": [],
   "source": [
    "## With 160 shifts\n",
    "total_shifts = 160\n",
    "shifts = [ts.shift(x).rename(f\"Diet shifted {x}\") for x in range(total_shifts)]\n",
    "res = pd.concat(shifts,axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:26.376283Z",
     "start_time": "2020-10-23T22:13:26.357739Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res_corr = res.corr()[['Diet shifted 0']]\n",
    "display(res_corr.iloc[:24].style.background_gradient())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:39.225795Z",
     "start_time": "2020-10-23T22:13:39.055463Z"
    }
   },
   "outputs": [],
   "source": [
    "res_corr.plot(figsize=(12,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACF & PACF  Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation Function Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - \"The **autocorrelation function** is a function that represents autocorrelation of a time series as a function of the time lag.\"\n",
    "- The autocorrelation function tells interesting stories about trends and seasonality. For example, if the original time series repeats itself every five days, you would expect to see a spike in the autocorrelation function at 5 days.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:56.072077Z",
     "start_time": "2020-10-23T22:13:55.899607Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,4)\n",
    "ts = trends['diet']\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:57.077831Z",
     "start_time": "2020-10-23T22:13:56.914058Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:57.527878Z",
     "start_time": "2020-10-23T22:13:57.394971Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.graphics.tsaplots as tsa\n",
    "\n",
    "tsa.plot_acf(ts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:58.174291Z",
     "start_time": "2020-10-23T22:13:58.012375Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot differenced data\n",
    "ts_diff = ts.diff().dropna()\n",
    "ts_diff.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:58.739599Z",
     "start_time": "2020-10-23T22:13:58.570579Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(ts_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:13:59.419393Z",
     "start_time": "2020-10-23T22:13:59.294210Z"
    }
   },
   "outputs": [],
   "source": [
    "tsa.plot_acf(ts_diff);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial-Autocorrelation Function Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> \"The **partial autocorrelation function** can be interpreted as a regression of the series against its past lags.\n",
    " \n",
    " > It helps you come up with a possible order for the auto regressive term. The terms can be interpreted the same way as a standard linear regression, that is the contribution of a change in that particular lag while holding others constant. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:14:01.646732Z",
     "start_time": "2020-10-23T22:14:01.496755Z"
    }
   },
   "outputs": [],
   "source": [
    "tsa.plot_pacf(ts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:14:02.358647Z",
     "start_time": "2020-10-23T22:14:02.103886Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "plot_acf(ts);\n",
    "plot_pacf(ts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ARMA MODELS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive Model (AR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Today = constant + slope} \\times \\text{yesterday + noise} $$\n",
    "\n",
    "Or, mathematically:\n",
    "\n",
    "$$\\large Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t$$\n",
    "\n",
    "> Some notes based on this formula:\n",
    "- If the slope is 0, the time series is a white noise model with mean $\\mu$\n",
    "- If the slope is not 0, the time series is autocorrelated\n",
    "- Bigger slope means bigger autocorrelation\n",
    "- When there is a negative slope, the time series follows an oscillatory process\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-arma-models-online-ds-pt-100719/master/images/AR_model.png\" width=90%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The  Moving Average Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The weighted sum of today's and yesterday's noise.\n",
    "\n",
    "In words, the mathematical idea is the following:\n",
    "\n",
    "$$ \\text{Today = Mean + Noise + Slope} \\times \\text{yesterday's noise} $$\n",
    "\n",
    "Or, mathematically:\n",
    "$$\\large Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}$$\n",
    "\n",
    "> Some notes based on this formula:\n",
    "- If the slope is 0, the time series is a white noise model with mean $\\mu$\n",
    "- If the slope is not 0, the time series is autocorrelated and depends on the previous white noise process\n",
    "- Bigger slope means bigger autocorrelation\n",
    "- When there is a negative slope, the time series follow an oscillatory process\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-arma-models-onl01-dtsc-pt-041320/master/images/MA_model.png\" width=90%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-order AR and MA models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's look at the formulas of AR and MA again:\n",
    "\n",
    "- AR: $Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t$\n",
    "- MA: $Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}$\n",
    "\n",
    "Note that these models are constructed in a way that processes only depend directly on the previous observation in the process. These models are so-called \"1st order models\", and denoted by AR(1) and MA(1) processes respectively. Let's look at AR(2) and MA(2).\n",
    "\n",
    "- AR(2): $$Y_t = \\mu + \\phi_1 * Y_{t-1}+\\phi_2 * Y_{t-2}+\\epsilon_t$$\n",
    "- MA(2): $$Y_t = \\mu +\\epsilon_t + \\theta_1 * \\epsilon_{t-1}+ \\theta_2 * \\epsilon_{t-2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARMA models\n",
    "\n",
    "- Combination of AR & MA models.\n",
    "    - regression on past values takes place (AR part) \n",
    "    - and also that the error term is modeled as a linear combination of error terms of the recent past (MA part).\n",
    "  \n",
    "  \n",
    "  \n",
    "- **Generally, one denotes ARMA as ARMA(p, q).**\n",
    "\n",
    "\n",
    "- An ARMA(2,1) model is given by:\n",
    "\n",
    " $$Y_t = \\mu + \\phi_1 Y_{t-1}+\\phi_2 Y_{t-2}+ \\theta \\epsilon_{t-1}+\\epsilon_t$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DETERMINING AR(P) and MA(Q) FROM READING PACF/ACF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INFO FROM LESSONS:\n",
    "\n",
    "- AR(p):\n",
    "    - ACF for AR(p) would be strong until lag of p, then stagnant, then trail off. \n",
    "    - PACF for AR(p): Generally no correlation for lag values beyond p.\n",
    "- MA(q):\n",
    "    - ACF for MA(q) would show strong correlation up to a lag of q, the immedately delcine to minimal/no correction.\n",
    "    - PACF would show strong relationship to the lag and tailing off to no correlation afterwards.\n",
    "   \n",
    "\n",
    "| Param| AR(p)   |   MA(q)  | ARMA(p,q)|\n",
    "|------|------|------|------|\n",
    "|   ACF | Tails off   |  Cuts off after lag q |  Tails off   |\n",
    "|   PACF | Cuts off after lag p  |   Tails off  |  Tails off  |\n",
    " \n",
    " \n",
    "#### INFO FROM UDEMY\n",
    "\n",
    "- **USE ACF TO JUDGE IF MA OR AR COMPONENTS:**\n",
    "    - If lag 1 is positive: AR\n",
    "    - If lag 1 is negatige: MA\n",
    "    \n",
    "- **PACF is best for picking AR (p)**\n",
    "- **ACF is best for picking MA(q)**\n",
    "    - If sharp drop off at lag of k (k= point on x axis) means use an AR model of order k.\n",
    "    - If slow gradual decline: use MA\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA MODELS:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ARIMA Time Series Model\n",
    "\n",
    "One of the most common methods used in time series forecasting is known as the ARIMA model, which stands for **AutoregRessive Integrated Moving Average**. ARIMA is a model that can be fitted to time series data in order to better understand or predict future points in the series.\n",
    "\n",
    "Let's have a quick introduction to ARIMA. The ARIMA forecasting for a stationary time series is nothing but a linear (like a linear regression) equation. The predictors depend on the parameters (p,d,q) of the ARIMA model:\n",
    "\n",
    "### Number of AR (Auto-Regressive) terms (p): \n",
    "\n",
    "`p` is the auto-regressive part of the model. It allows us to incorporate the effect of past values into our model. Intuitively, this would be similar to stating that it is likely to rain tomorrow if it has been raining for past 3 days. AR terms are just lags of dependent variable. For instance if p is 5, the predictors for x(t) will be x(t-1)….x(t-5).\n",
    "\n",
    "### Number of Differences (d):\n",
    "\n",
    "`d` is the **Integrated** component of an ARIMA model. This value is concerned with the amount of differencing as it identifies the number of lag values to subtract from the current observation. Intuitively, this would be similar to stating that it is likely to rain tomorrow if the difference in amount of rain in the last *n* days is small. \n",
    "\n",
    "### Number of MA (Moving Average) terms (q): \n",
    "\n",
    "`q` is the moving average part of the model which is used to set the error of the model as a linear combination of the error values observed at previous time points in the past. MA terms form lagged forecast errors in prediction equation. For instance if q is 5, the predictors for x(t) will be e(t-1)….e(t-5) where `e(i)` is the difference between the moving average at ith instant and actual value.\n",
    "\n",
    "These three distinct integer values, (p, d, q), are used to parametrize ARIMA models. Because of that, ARIMA models are denoted with the notation `ARIMA(p, d, q)`. Together these three parameters account for seasonality, trend, and noise in datasets:\n",
    "\n",
    "* `(p, d, q)` are the non-seasonal parameters described above.\n",
    "* `(P, D, Q)` follow the same definition but are applied to the seasonal component of the time series. \n",
    "* The term `s` is the periodicity of the time series (4 for quarterly periods, 12 for yearly periods, etc.).\n",
    "\n",
    "A detailed article on these parameters is available [HERE](https://www.quantstart.com/articles/Autoregressive-Integrated-Moving-Average-ARIMA-p-d-q-Models-for-Time-Series-Analysis).\n",
    "\n",
    "The seasonal ARIMA method can appear daunting because of the multiple tuning parameters involved. In the next section, we will describe how to automate the process of identifying the optimal set of parameters for the seasonal ARIMA time series model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: SARIMA Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Repo folder > labs from class> sect_38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T17:27:18.053121Z",
     "start_time": "2020-10-16T17:27:17.718723Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_acf(ts);\n",
    "plot_pacf(ts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pmdarima.auto_arima`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.918700Z",
     "start_time": "2020-10-16T16:18:25.713Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U pmdarima\n",
    "import pmdarima\n",
    "pmdarima.auto_arima?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.422px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
